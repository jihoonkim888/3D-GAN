{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ce83c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "mini_batch_size = 50\n",
    "lr_G = 0.0025\n",
    "lr_D = 0.0001\n",
    "beta1 = 0.5\n",
    "workers = 0\n",
    "dataset_name = 'shapenet_v2'\n",
    "obj = 'airplane'\n",
    "dim = 128\n",
    "noise_dim = 200 # latent space vector dim\n",
    "in_channels = 512 # convolutional channels\n",
    "run_parallel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cbc53c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  42\n",
      "batch size: 100 mini batch: 50 k: 2\n",
      "dim: 128\n",
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "k = int(batch_size / mini_batch_size)\n",
    "print('batch size:', batch_size, 'mini batch:', mini_batch_size, 'k:', k)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 42\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "print('dim:', dim)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stock-reset",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'shapenet_v2_airplane_r128.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m data_filename \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mshapenet_v2_airplane_r128\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m f \u001b[39m=\u001b[39m h5py\u001b[39m.\u001b[39;49mFile(data_filename \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m.h5\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m dataset \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39marray(f[\u001b[39mlist\u001b[39m(f\u001b[39m.\u001b[39mkeys())[\u001b[39m0\u001b[39m]])\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, original_dim, original_dim, original_dim))\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m      5\u001b[0m \u001b[39mif\u001b[39;00m inverse_scale \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\diss\\lib\\site-packages\\h5py\\_hl\\files.py:507\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jihoon/miniconda3/envs/diss/lib/site-packages/h5py/_hl/files.py?line=501'>502</a>\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jihoon/miniconda3/envs/diss/lib/site-packages/h5py/_hl/files.py?line=502'>503</a>\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/Jihoon/miniconda3/envs/diss/lib/site-packages/h5py/_hl/files.py?line=503'>504</a>\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jihoon/miniconda3/envs/diss/lib/site-packages/h5py/_hl/files.py?line=504'>505</a>\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[0;32m    <a href='file:///c%3A/Users/Jihoon/miniconda3/envs/diss/lib/site-packages/h5py/_hl/files.py?line=505'>506</a>\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jihoon/miniconda3/envs/diss/lib/site-packages/h5py/_hl/files.py?line=506'>507</a>\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39;49mswmr)\n\u001b[0;32m    <a href='file:///c%3A/Users/Jihoon/miniconda3/envs/diss/lib/site-packages/h5py/_hl/files.py?line=508'>509</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Jihoon/miniconda3/envs/diss/lib/site-packages/h5py/_hl/files.py?line=509'>510</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\diss\\lib\\site-packages\\h5py\\_hl\\files.py:220\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Jihoon/miniconda3/envs/diss/lib/site-packages/h5py/_hl/files.py?line=217'>218</a>\u001b[0m     \u001b[39mif\u001b[39;00m swmr \u001b[39mand\u001b[39;00m swmr_support:\n\u001b[0;32m    <a href='file:///c%3A/Users/Jihoon/miniconda3/envs/diss/lib/site-packages/h5py/_hl/files.py?line=218'>219</a>\u001b[0m         flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> <a href='file:///c%3A/Users/Jihoon/miniconda3/envs/diss/lib/site-packages/h5py/_hl/files.py?line=219'>220</a>\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mopen(name, flags, fapl\u001b[39m=\u001b[39;49mfapl)\n\u001b[0;32m    <a href='file:///c%3A/Users/Jihoon/miniconda3/envs/diss/lib/site-packages/h5py/_hl/files.py?line=220'>221</a>\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Jihoon/miniconda3/envs/diss/lib/site-packages/h5py/_hl/files.py?line=221'>222</a>\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mopen(name, h5f\u001b[39m.\u001b[39mACC_RDWR, fapl\u001b[39m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'shapenet_v2_airplane_r128.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "data_filename = f'{dataset_name}_{obj}_r{dim}'\n",
    "\n",
    "f = h5py.File(data_filename + '.h5', 'r')\n",
    "dataset = torch.from_numpy(np.array(f[list(f.keys())[0]]).reshape(-1, 1, dim, dim, dim)).to(torch.float)\n",
    "\n",
    "print('dataset shape:', dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480cc71e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# GAN Structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc01451",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generator summary\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1            [-1, 1, 131072]      26,345,472\n",
      "   ConvTranspose3d-2      [-1, 128, 16, 16, 16]       2,097,152\n",
      "       BatchNorm3d-3      [-1, 128, 16, 16, 16]             256\n",
      "              ReLU-4      [-1, 128, 16, 16, 16]               0\n",
      "   ConvTranspose3d-5       [-1, 64, 32, 32, 32]         524,288\n",
      "       BatchNorm3d-6       [-1, 64, 32, 32, 32]             128\n",
      "              ReLU-7       [-1, 64, 32, 32, 32]               0\n",
      "   ConvTranspose3d-8       [-1, 32, 64, 64, 64]         131,072\n",
      "       BatchNorm3d-9       [-1, 32, 64, 64, 64]              64\n",
      "             ReLU-10       [-1, 32, 64, 64, 64]               0\n",
      "  ConvTranspose3d-11     [-1, 1, 128, 128, 128]           2,048\n",
      "          Sigmoid-12     [-1, 1, 128, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 29,100,480\n",
      "Trainable params: 29,100,480\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 285.00\n",
      "Params size (MB): 111.01\n",
      "Estimated Total Size (MB): 396.01\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "Discriminator summary\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1       [-1, 32, 64, 64, 64]           2,048\n",
      "       BatchNorm3d-2       [-1, 32, 64, 64, 64]              64\n",
      "         LeakyReLU-3       [-1, 32, 64, 64, 64]               0\n",
      "            Conv3d-4       [-1, 64, 32, 32, 32]         131,072\n",
      "       BatchNorm3d-5       [-1, 64, 32, 32, 32]             128\n",
      "         LeakyReLU-6       [-1, 64, 32, 32, 32]               0\n",
      "            Conv3d-7      [-1, 128, 16, 16, 16]         524,288\n",
      "       BatchNorm3d-8      [-1, 128, 16, 16, 16]             256\n",
      "         LeakyReLU-9      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-10         [-1, 256, 8, 8, 8]       2,097,152\n",
      "      BatchNorm3d-11         [-1, 256, 8, 8, 8]             512\n",
      "        LeakyReLU-12         [-1, 256, 8, 8, 8]               0\n",
      "           Linear-13                    [-1, 1]         131,073\n",
      "          Sigmoid-14                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 2,886,593\n",
      "Trainable params: 2,886,593\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 8.00\n",
      "Forward/backward pass size (MB): 255.00\n",
      "Params size (MB): 11.01\n",
      "Estimated Total Size (MB): 274.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.GAN import Discriminator, Generator, weights_init\n",
    "\n",
    "netG = Generator(in_channels=256, out_dim=dim, out_channels=1, noise_dim=noise_dim)\n",
    "if run_parallel:\n",
    "    netG = torch.nn.DataParallel(netG)\n",
    "netG = netG.to(device)\n",
    "netG.apply(weights_init)\n",
    "# noise = torch.rand(1, noise_dim).to(device)\n",
    "# generated_volume = netG(noise)\n",
    "# print(\"Generator output shape\", generated_volume.shape)\n",
    "netD = Discriminator(in_channels=1, out_conv_channels=256, dim=dim)\n",
    "if run_parallel:\n",
    "    netD = torch.nn.DataParallel(netD)\n",
    "netD = netD.to(device)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "# # Establish convention for real and fake labels during training\n",
    "# real_label = 1.\n",
    "# fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr_D, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr_G, betas=(beta1, 0.999))\n",
    "\n",
    "# out = netD(generated_volume)\n",
    "# print(\"Discriminator output\", out.item())\n",
    "\n",
    "print(\"\\n\\nGenerator summary\\n\\n\")\n",
    "summary(netG, (1, noise_dim))\n",
    "print(\"\\n\\nDiscriminator summary\\n\\n\")\n",
    "summary(netD, (1, dim, dim, dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0a849",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training and Testing 3D-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd0b27",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    num_workers=workers,\n",
    ")\n",
    "\n",
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d0e98",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Running Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0abfa59",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Lists to keep track of progress\n",
    "G_losses = []\n",
    "D_real_losses = []\n",
    "D_fake_losses = []\n",
    "real_accuracies = []\n",
    "fake_accuracies = []\n",
    "start_epoch = 0\n",
    "iters = 0\n",
    "\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "os.makedirs(f'./weights/{data_filename}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b7539",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "\n",
    "# Training Loop\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in tqdm(range(start_epoch, start_epoch+num_epochs)):\n",
    "    # For each batch in the dataloader\n",
    "    lst_train_acc_real = []\n",
    "    lst_train_acc_fake = []\n",
    "    for i, data_all in enumerate(dataloader, 0):\n",
    "        data_split = torch.split(data_all, mini_batch_size)\n",
    "        optimizerD.zero_grad()\n",
    "#         print('reset netD grads')\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        for j in range(len(data_split)):\n",
    "            data = data_split[j]\n",
    "#             print(data.shape)\n",
    "            real_cpu = data.to(device)\n",
    "            b_size = real_cpu.size(0)\n",
    "            label_real = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "            label_fake = torch.full((b_size,), fake_label, dtype=torch.float, device=device)\n",
    "            # Forward pass real batch through D\n",
    "            output_real = netD(real_cpu).view(-1)\n",
    "            # Calculate loss on all-real batch\n",
    "            D_x = output_real.mean().item()\n",
    "            train_acc_real = torch.sum((output_real > 0.5).to(int)==label_real) / b_size\n",
    "            lst_train_acc_real.append(train_acc_real.item())\n",
    "            errD_real = criterion(output_real, label_real) / len(data_split)\n",
    "            errD_real.backward()\n",
    "\n",
    "            ## Train with all-fake batch\n",
    "            # Generate batch of latent vectors\n",
    "            noise = torch.rand(b_size, noise_dim, device=device)\n",
    "            # Generate fake image batch with G\n",
    "            fake = netG(noise).detach()\n",
    "            output_fake = netD(fake).view(-1)\n",
    "            D_G_z1 = output_fake.mean().item()\n",
    "            train_acc_fake = torch.sum((output_fake > 0.5).to(int) == label_fake) / b_size\n",
    "            lst_train_acc_fake.append(train_acc_fake.item())\n",
    "            errD_fake = criterion(output_fake, label_fake) / len(data_split)\n",
    "            errD_fake.backward()\n",
    "\n",
    "            errD = errD_real + errD_fake        \n",
    "        \n",
    "        # update D only if classification acc is less than 80% for stability\n",
    "#         if (i+1) % k == 0 or (i+1) == len(dataloader):\n",
    "            if j==len(data_split)-1:\n",
    "                acc_real_mean = np.mean(lst_train_acc_real)\n",
    "                acc_fake_mean = np.mean(lst_train_acc_fake)\n",
    "                update = ((acc_real_mean + acc_fake_mean) / 2) < 0.8\n",
    "                if update:\n",
    "                    optimizerD.step()  # update the weights only after accumulating k small batches\n",
    "#                     print('updated optD')\n",
    "\n",
    "                optimizerD.zero_grad()  # reset gradients for accumulation for the next large batch\n",
    "                lst_train_acc_real = []\n",
    "                lst_train_acc_fake = []\n",
    "            \n",
    "        \n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        # fake labels are real for generator cost\n",
    "        optimizerG.zero_grad()\n",
    "#         print('reset netG grads')\n",
    "        for j in range(len(data_split)):\n",
    "            label = torch.full((b_size,), real_label, dtype=torch.float, device=device)  \n",
    "            # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "            fake = netG(noise)\n",
    "            output = netD(fake).view(-1)\n",
    "            errG = criterion(output, label) / len(data_split)\n",
    "            errG.backward()\n",
    "\n",
    "\n",
    "            D_G_z2 = output.mean().item()\n",
    "#             if (i+1) % k == 0 or (i+1) == len(dataloader):\n",
    "            if j==len(data_split)-1:\n",
    "                optimizerG.step()  # update the weights only after accumulating k small batches\n",
    "                optimizerG.zero_grad()  # reset gradients for accumulation for the next large_batch\n",
    "#                 print('updated optG')\n",
    "\n",
    "            # Save Losses for plotting later\n",
    "            G_losses.append(errG.item())\n",
    "            D_fake_losses.append(errD_fake.item())\n",
    "            D_real_losses.append(errD_real.item())\n",
    "            fake_accuracies.append(train_acc_fake.item())\n",
    "            real_accuracies.append(train_acc_real.item())\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 10 == 0: # print progress every epoch\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, start_epoch+num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "            \n",
    "        iters += 1\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        # save network weights\n",
    "        netG_filename = f'./weights/{data_filename}/netG_e{epoch}_r{dim}_weights.pth'\n",
    "        netD_filename = f'./weights/{data_filename}/netD_e{epoch}_r{dim}_weights.pth'\n",
    "        torch.save(netG.state_dict(), netG_filename)\n",
    "        torch.save(netD.state_dict(), netD_filename)\n",
    "        print('saved network weights', netG_filename)\n",
    "\n",
    "\n",
    "torch.save(netG.state_dict(), f'./weights/{data_filename}/netG_e{epoch}_r{dim}_weights.pth')\n",
    "torch.save(netD.state_dict(), f'./weights/{data_filename}/netD_e{epoch}_r{dim}_weights.pth')\n",
    "start_epoch = epoch # change start to the current"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a21353",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174248ee",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Convergence Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b30a82f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_real_losses, label=\"D_real\")\n",
    "plt.plot(D_fake_losses, label=\"D_fake\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim([0, 5])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Discriminator Accuracies During Training\")\n",
    "plt.plot(real_accuracies, label=\"acc_real\")\n",
    "plt.plot(fake_accuracies, label=\"acc_fake\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ef0b2d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b2aac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Real Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f52947",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "real_sample = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0346f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    s = real_sample[i][0]\n",
    "    ax = plt.figure().add_subplot(projection='3d')\n",
    "#     ax = plt.figure(figsize=(10, 10)).add_subplot(projection='3d')\n",
    "    ax.voxels(s)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da0c04",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Generate fake samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be921be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fake_samples = []\n",
    "\n",
    "for i in tqdm(range(0, epoch, 20)):    \n",
    "    try:\n",
    "    \n",
    "    #     file_netD = 'weights/shapnet_v2_car_r128/' + 'netD_shapenet_v2_car_r128_e' + f'{i*10}' + '_weights.pth'\n",
    "        file_netG = f'weights/{data_filename}/netG_e{i}_r{dim}_weights.pth'\n",
    "        print(file_netG)\n",
    "        netG.load_state_dict(torch.load(file_netG))\n",
    "    #     netD.load_state_dict(torch.load(file_netD))\n",
    "\n",
    "        fixed_noise = torch.rand(5, noise_dim, device=device)\n",
    "        with torch.no_grad():\n",
    "            fake = netG(fixed_noise).detach().cpu().numpy()\n",
    "        fake_samples.append(fake)\n",
    "        print('generated fake samples')\n",
    "        \n",
    "        \n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('epoch', i, 'failed')\n",
    "\n",
    "fake_samples = np.array(fake_samples)\n",
    "\n",
    "os.makedirs('./fake_samples', exist_ok=True)\n",
    "h5_filename = f'./fake_samples/{data_filename}_r{dim}.h5'\n",
    "with h5py.File(h5_filename, \"w\") as f:\n",
    "    dset = f.create_dataset(\"data\", data=fake_samples)\n",
    "    print(h5_filename, 'saved')\n",
    "\n",
    "print('fake sample shape:', fake_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f4754",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b17cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
